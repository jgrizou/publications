\section{Conclusions, Limitations And Future Work}
\label{sec:LimitationAndFutureWork}
%
In this work, we presented an interactive learning system that can learn the meaning of instructions while learning a new task. We considered the case of spoken words but of particular interest is the possibility to use the same system with other modalities, such as facial expressions or hand gestures. This allows different users to use the system according to their own preferences, skills, and limitations. We tested our experiment on a real robot and showed that knowledge acquired from a first experiment can be reused later as a source of known information. 

Our approach assumes that the robot is equipped with planning skills and can not be used if several hypothesis are fully symmetric as they will not be distinguishable. This problem can be solved by redefining the set of hypothesis, for instance by adding a ''stop'' action valid only at the goal states. 

In order to make the learning problem tractable, we assumed that the robot had access to a predefined set of tasks. The robot will then find the hypothesis that best approximates the true one. We could extend this and follow a particle filter like approach to be able to generate new hypothesis online and potentially find a better one.

%The current work is a starting point and some assumptions have been included. The interaction protocol is constrained to be turn taking and the possible meanings are limited to feedback or guidance on the robot's action.
%
In the future we will study how to extend the proposed approach to more complex scenarios, e.g. how it scales to continuous domain. We will also consider how more complex instructions can be included in our formalism since the teaching models used spontaneously by people can be more complex than the simple meaning correspondences we assumed \cite{Thomaz2008,Cakmak2010}. Also the protocol could be enhanced to be more natural, the robot could ask questions \cite{cakmak2012designing} and accept asynchronous signals. An important aspect is to allow the user to teach the robot new macro-actions or macro-states and a first approach for that problem is to use the options framework \cite{sutton1999between}.
%
%
%\section{Conclusions}
%In this work we presented an interactive learning system that can learn a task from unknown and noisy teaching signals while simultaneously estimating the associated meaning of such natural language utterances. 
%In this work we presented an interactive learning system that can learn the meaning of teaching signals while learning a new skill. We considered the case of spoken words but of particular interest is the possibility to use the same system with other modalities, such as facial expressions or hand gestures. 
%A robot that interacts repeatedly with the same teacher will be able to reuse part of its knowledge about the used teaching signals when acquiring new tasks.
%Our algorithm is an \textit{Expectation-Maximization} approach where the hidden variables are the true meanings of the words provided by the teacher. The algorithm is able to learn in this setting due to some assumptions about the class of problems that the robot is able to acquire and by finding the pairs of meaning-task that are more ``coherent'' in a statistical setting. The meanings are learned with standard classification algorithms where the best results are achieved with a simple gaussian classifier.
%We considered how the policy of the robot influences learning and observed that if the robot acts according to its current estimate of what the optimal policy is, the learning rate is higher. We studied two cases: a) the teacher provides feedback signals, i.e. a binary reward signal and b) the teacher provides guidance signals, i.e. an instruction of what the optimal action is. The algorithm works in both situations.
%Although we took such a difficult challenge of learning without assuming knowledge of the teaching signals, for a practical case it is more reasonable to combine pre-specified words with an adaptation to new words. This allows different users to use the system according to their own preferences, skills and limitations. The use of those extra sources of information is straightforward in our statistical formalism. 
%The main advantage of combining all the sources of information into the same algorithm is that mistakes in the teaching, e.g. the user presses the wrong button, can be corrected accurately. We observed that even with $30\%$ of errors in the feedback the system can identify the correct task with low uncertainty.
%Finally we tested our experiment in a real world implementation and showed that knowledge acquired from a first experiment can be reused later as a source of known information. A robot that interacts repeatedly with the same teacher will be able to reuse part of its knowledge about the used teaching signals when acquiring new tasks.